{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1331c356-f5de-4dcd-a79c-d159b12d6223",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-msssim\n",
    "!pip install faiss-cpu\n",
    "!pip install wandb\n",
    "!pip install sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e68bd0-a361-4ac1-a8c7-418ccc9de335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "\n",
    "import wandb\n",
    "import random\n",
    "\n",
    "import  torch, time, os, pickle\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from os import listdir\n",
    " \n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pytorch_msssim import ssim  # For SSIM metric\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4852e60-a774-4d3a-8812-174e2c08e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device as cuda if available\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c5bd2f-f667-48a3-963f-7ce82b3ebd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(epoch,y_,model_type):\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    z_ = torch.rand((batch_size, z_dim))\n",
    "    y_vec_ = torch.zeros((batch_size, class_num)) \\\n",
    "            .scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n",
    "    fake_images = G(z_,y_vec_).detach().cpu()\n",
    "    save_image(fake_images, f'outputs/'+model_type+str(epoch)+'.png', nrow=8, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf47f8a-50b5-49ad-9c0e-dbe64fe31314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generated_images():\n",
    "  folder_dir = \"/content/outputs/\"\n",
    "\n",
    "  for image in os.listdir(folder_dir):\n",
    "      img = mpimg.imread(folder_dir+image)\n",
    "      plt.imshow(img)\n",
    "      plt.axis('off')  \n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3701a621-da96-42b6-8c8d-b1ce8a5b77ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorCGAN(nn.Module):\n",
    "    def __init__(self, nz=100, nc=1, input_size=32, class_num=10):\n",
    "        super(GeneratorCGAN, self).__init__()\n",
    "        self.nz = nz\n",
    "        self.nc = nc\n",
    "        self.input_size = input_size\n",
    "        self.class_num = class_num\n",
    "\n",
    "      \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.nz + self.class_num, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128 * (self.input_size // 4) * (self.input_size // 4)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, self.nc, 4, 2, 1),\n",
    "            nn.Tanh(),  \n",
    "        )\n",
    "\n",
    "        self.apply(self._initialize_weights)\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        x = torch.cat([input, label], 1)\n",
    "        \n",
    "\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 128, (self.input_size // 4), (self.input_size // 4))\n",
    "\n",
    "    \n",
    "        x = self.deconv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self, m):\n",
    "        if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.normal_(m.weight, 0, 0.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f431dd3-6e51-4c9e-a953-88bf16adaf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_set(batch_size):\n",
    "\n",
    "    # Define transformations (convert to tensor + normalize)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "    train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "    dataloader = DataLoader(train_dataset,  batch_size)\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "data_loader = data_set(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0d3649-13e5-44e7-9f0e-e42a60eb1895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "input_size = 28\n",
    "\n",
    "z_dim = 62\n",
    "\n",
    "class_num = 10\n",
    "\n",
    "sample_num = class_num ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c34f818-f5ff-4275-9dcd-4029a657a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_mmd(x, y, degree=3, gamma=None, coef0=1):\n",
    "    # Returns the polynomial MMD between x and y.\n",
    "\n",
    "    # Reshape to 2D ensuring the same number of features\n",
    "    x = x.view(x.size(0), -1)\n",
    "    y = y.view(y.size(0), -1)\n",
    "\n",
    "    # Check if feature dimensions match\n",
    "    if x.shape[1] != y.shape[1]:\n",
    "        raise ValueError(f\"Feature dimensions do not match: x has {x.shape[1]} features, y has {y.shape[1]} features. Ensure real and generated images have the same number of channels.\")\n",
    "\n",
    "    if gamma is None:\n",
    "        gamma = 1.0 / x.shape[1]\n",
    "    kernel_xx = (gamma * x.mm(x.t()) + coef0) ** degree\n",
    "    kernel_yy = (gamma * y.mm(y.t()) + coef0) ** degree\n",
    "    kernel_xy = (gamma * x.mm(y.t()) + coef0) ** degree\n",
    "    return kernel_xx.mean() + kernel_yy.mean() - 2 * kernel_xy.mean()\n",
    "\n",
    "\n",
    "\n",
    "def kernel_inception_distance(real_features, generated_features):\n",
    "    # Calculates the Kernel Inception Distance (KID) between real and generated features.\n",
    "\n",
    "    # Ensure real and generated features have the same number of channels\n",
    "    if real_features.shape[1] != generated_features.shape[1]:\n",
    "         real_features = real_features[:, :generated_features.shape[1], :, :]\n",
    "        \n",
    "\n",
    "    # Calculate KID using polynomial MMD\n",
    "    real_features, generated_features = torch.tensor(real_features), torch.tensor(generated_features)\n",
    "    return polynomial_mmd(real_features, generated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6696fef1-becc-48c2-95b0-6c2197ca6ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicialization(sample_num,z_dim,class_num):\n",
    "    sample_z_ = torch.zeros((sample_num, z_dim))\n",
    "\n",
    "    # Create fixed latent vectors (same noise for each class)\n",
    "    for i in range(class_num):\n",
    "        sample_z_[i * class_num] = torch.rand(1, z_dim)\n",
    "        for j in range(1, class_num):\n",
    "            sample_z_[i * class_num + j] = sample_z_[i * class_num]\n",
    "\n",
    "    # Create class labels for one-hot encoding\n",
    "    temp = torch.zeros((class_num, 1))\n",
    "    for i in range(class_num):\n",
    "        temp[i, 0] = i\n",
    "\n",
    "    # Repeat class labels to match the sample size\n",
    "    temp_y = torch.zeros((sample_num, 1))\n",
    "    for i in range(class_num):\n",
    "        temp_y[i * class_num: (i + 1) * class_num] = temp\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    sample_y_ = torch.zeros((sample_num, class_num)) \\\n",
    "        .scatter_(1, temp_y.type(torch.LongTensor), 1)\n",
    "\n",
    "    return sample_z_, sample_y_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8af3b-46a0-4c18-ac73-f4685ed1022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_processing(batch_size,z_dim,class_num,input_size,y_):\n",
    "\n",
    "  # Sample random noise and prepare label vectors\n",
    "\n",
    "        z_ = torch.rand((batch_size, z_dim))\n",
    "        y_vec_ = torch.zeros((batch_size, class_num)) \\\n",
    "            .scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n",
    "\n",
    "        y_fill_ = y_vec_.unsqueeze(2).unsqueeze(3) \\\n",
    "            .expand(batch_size, class_num, input_size, input_size)\n",
    "\n",
    "        return z_,y_vec_,y_fill_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e44b2c5-cdac-4c89-97dc-624a3a912c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(d_losses, g_losses,gan_type):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(d_losses, label='Discriminator Loss')\n",
    "    plt.plot(g_losses, label='Generator Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Losses '+gan_type)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    os.makedirs('Metrics', exist_ok=True)\n",
    "    plt.savefig('./Metrics/'+gan_type+'_generator_discriminator_losses.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e69570-ca7d-4e0b-be68-93b703e8635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssim_plot(SSIM_SCORES_EPOCHS,gan_type):\n",
    "    plt.title(\"SSIM for every Epoch\")\n",
    "    plt.plot(SSIM_SCORES_EPOCHS,color=\"green\")\n",
    "    plt.grid()\n",
    "    os.makedirs('Metrics', exist_ok=True)\n",
    "    plt.savefig('./Metrics/'+gan_type+'SSIM.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4dbe66-9455-447b-beec-e9759629b51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kid_plot(KID_SCORES_EPOCHS,gan_type):\n",
    "  plt.title(\"KID in every Epoch\")\n",
    "  plt.plot(KID_SCORES_EPOCHS,color=\"yellow\")\n",
    "  plt.grid()\n",
    "  plt.savefig('./Metrics/'+gan_type+'_KID_losses.png')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196259d4-7dfb-4c98-88c8-0a1c4f20a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cgan(d_loss_total,g_loss_total,x_,y_fill_,z_,y_vec_,y_real_,y_fake_):\n",
    "\n",
    "    ############################\n",
    "        # (1) Update D network: )\n",
    "        ###########################\n",
    "        # Train with all-real batch\n",
    "\n",
    "        optimizerD.zero_grad()\n",
    "\n",
    "        output = D(x_, y_fill_)\n",
    "        errD_real = BCE_loss(output, y_real_)\n",
    "\n",
    "        G_ = G(z_, y_vec_)\n",
    "        D_fake = D(G_, y_fill_)\n",
    "        errD_fake  = BCE_loss(D_fake, y_fake_)\n",
    "\n",
    "        D_loss = errD_real + errD_fake\n",
    "\n",
    "        d_loss_total +=  errD_real.item() + errD_fake.item()\n",
    "\n",
    "        D_loss.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ###########################\n",
    "        optimizerG.zero_grad()\n",
    "\n",
    "        G_ = G(z_, y_vec_)\n",
    "        output = D(G_, y_fill_)\n",
    "        errG = BCE_loss(output, y_real_)\n",
    "\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        g_loss_total += errG.item()\n",
    "\n",
    "        # Calculate KID\n",
    "        real_images = torch.cat([x_, y_fill_], 1)\n",
    "        fake = G_\n",
    "\n",
    "        return D_loss, errG, real_images, fake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f32f01-2d97-464a-9421-bfa745b9aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_type,G,D,version):\n",
    "\n",
    "      # Start a new wandb run to track this script.\n",
    "      run = wandb.init(\n",
    "\n",
    "          # Set the wandb entity.\n",
    "          entity=\"lorrayne-reis-silva-city-university-of-london\",\n",
    "          # Set the wandb project where this run will be logged.\n",
    "          project=model_type+version,\n",
    "          # Track hyperparameters and run metadata.\n",
    "          config={\n",
    "              \"learning_rate_G\": 0.000055,\n",
    "              \"learning_rate_D\": 0.0002,\n",
    "              \"architecture\": model_type+version,\n",
    "              \"dataset\": \"Fashion-MNIST\",\n",
    "              \"epochs\": 20,\n",
    "          },\n",
    "      )\n",
    "\n",
    "\n",
    "      d_losses = []\n",
    "      g_losses = []\n",
    "      SSIM_SCORES = []\n",
    "      KID_SCORES = []\n",
    "\n",
    "\n",
    "      sample_z_, sample_y_ = inicialization(sample_num,z_dim,class_num)\n",
    "\n",
    "      # Labels for real and fake samples\n",
    "      y_real_, y_fake_ = torch.ones(batch_size, 1), torch.zeros(batch_size, 1)\n",
    "\n",
    "      # Start training\n",
    "      D.train()\n",
    "\n",
    "      num_epochs=20\n",
    "\n",
    "      for epoch in range(num_epochs):\n",
    "\n",
    "          d_loss_total = 0.0\n",
    "          g_loss_total = 0.0\n",
    "\n",
    "          G.train()\n",
    "\n",
    "          for iter, (x_, y_) in enumerate(data_loader):\n",
    "              if iter == data_loader.dataset.__len__() // batch_size:\n",
    "                  break\n",
    "                  \n",
    "\n",
    "              z_,y_vec_,y_fill_ = label_processing(batch_size,z_dim,class_num,input_size,y_)\n",
    "              x_ = x_.view(x_.size(0), 1, input_size, input_size)\n",
    "\n",
    "              if model_type in [\"CGAN\",\"CGAN_complete\",\"InfoGan-CGAN\"]:\n",
    "                D_loss, errG, real_images, fake = train_cgan(d_loss_total,g_loss_total,x_,y_fill_,z_,y_vec_,y_real_,y_fake_)\n",
    "\n",
    "              elif model_type in [\"ACGAN\",\"InfoGAN-ACGAN\",\"CGAN_ACGAN\"]:\n",
    "                D_loss, errG, real_images, fake = train_acgan(D, G, d_loss_total, g_loss_total, y_real_, y_fake_, y_vec_, x_, z_, y_fill_)\n",
    "\n",
    "\n",
    "              # Calculate KID\n",
    "              kid = kernel_inception_distance(real_images.detach().cpu(), fake.detach().cpu())\n",
    "\n",
    "\n",
    "              # Calculate SSIM\n",
    "              score = ssim(x_, fake.detach())\n",
    "\n",
    "\n",
    "              # Logging\n",
    "              if (iter + 1) % 100 == 0:\n",
    "\n",
    "                d_losses.append(D_loss.item())\n",
    "                g_losses.append(errG.item())\n",
    "                run.log({\"D_loss\": D_loss.item(), \"G_loss\": errG.item()})\n",
    "                KID_SCORES.append(kid.item())\n",
    "                SSIM_SCORES.append(score.detach().cpu())\n",
    "\n",
    "\n",
    "                print(\"Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f\" % (\n",
    "                      epoch + 1, iter + 1,\n",
    "                      data_loader.dataset.__len__() // batch_size,\n",
    "                      D_loss.item(), errG.item()\n",
    "                  ))\n",
    "\n",
    "\n",
    "          if (epoch+1) in [1,10,15,20]:\n",
    "                    save_images(epoch+1,y_,model_type)\n",
    "\n",
    "\n",
    "          os.makedirs('Epochs', exist_ok=True)\n",
    "          torch.save(G.state_dict(), f'./Epochs/G_epoch_'+model_type+'_'+str(epoch)+'.pth')\n",
    "          torch.save(D.state_dict(), f'./Epochs/D_epoch_'+model_type+'_'+str(epoch)+'.pth')\n",
    "\n",
    "    \n",
    "\n",
    "      return d_losses , g_losses , SSIM_SCORES,KID_SCORES\n",
    "      run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b11cce-9fce-4bf1-916b-55378a69d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rates\n",
    "\n",
    "lrG= 0.0003\n",
    "lrD=0.0002\n",
    "beta1=0.5\n",
    "beta2=0.99\n",
    "\n",
    "# Define model\n",
    "G = GeneratorCGAN(nz=z_dim, nc=1, input_size=input_size, class_num=class_num)\n",
    "D = Discriminator(nz=1, nc=1, input_size=input_size, class_num=class_num)\n",
    "\n",
    "print(G)\n",
    "print(D)\n",
    "\n",
    "#Optimizers\n",
    "optimizerG = optim.Adam(G.parameters(), lr=lrG, betas=(beta1, beta2))\n",
    "optimizerD = optim.Adam(D.parameters(), lr=lrD, betas=(beta1, beta2))\n",
    "\n",
    "# Define loss\n",
    "BCE_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb539c55-4fbf-451d-970c-361a51670a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_losses_cgan_complete ,g_losses_cgan_complete , SSIM_SCORES_cgan_complete ,KID_SCORES_cgan_complete = train_model(\"CGAN_complete\",G,D,\"35\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39b73fd-6be8-4bb2-84fb-9ea724346247",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(d_losses_cgan_complete, g_losses_cgan_complete,\"CGAN_complete\")\n",
    "ssim_plot(SSIM_SCORES_cgan_complete,\"CGAN_complete\")\n",
    "kid_plot(KID_SCORES_cgan_complete,\"CGAN_complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
